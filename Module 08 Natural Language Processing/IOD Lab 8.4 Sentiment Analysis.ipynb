{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYvQOebqLcfM"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JWvLBewLcfP"
   },
   "source": [
    "# Lab 8.4: Sentiment Analysis\n",
    "\n",
    "This lab performs sentiment analysis on sentiment-labelled sentences using two types of feature extraction - a count vectorizer and TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbhmKC6NLcfS"
   },
   "source": [
    "Based on the video tutorial **Text Classification with Machine Learning,SpaCy and Scikit(Sentiment Analysis)** by **Jesse E. Agbe (JCharis)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnuAMgbhLcfV"
   },
   "source": [
    "## Data Source: UCI\n",
    "### UCI - Machine Learning Repository\n",
    "- Center for Machine Learning and Intelligent Systems\n",
    "\n",
    "The [**UCI Machine Learning Repository**](http://archive.ics.uci.edu/about) is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms.\n",
    "\n",
    "### Dataset\n",
    "- [Sentiment Labelled Sentences Data Set](http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)\n",
    "\n",
    "### Abstract\n",
    "The dataset contains sentences labelled with positive or negative sentiment.\n",
    "\n",
    "- Data Set Characteristics: Text\n",
    "- Number of Instances: 3000\n",
    "- Area: N/A\n",
    "- Attribute Characteristics: N/A\n",
    "- Number of Attributes: N/A\n",
    "- Date Donated: 2015-05-30\n",
    "- Associated Tasks: Classification\n",
    "- Missing Values? N/A\n",
    "\n",
    "### Source\n",
    "Dimitrios Kotzias dkotzias '@' ics.uci.edu\n",
    "\n",
    "### Data Set Information\n",
    "This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\n",
    "\n",
    "Please cite the paper if you want to use it :)\n",
    "\n",
    "It contains sentences labelled with positive or negative sentiment.\n",
    "\n",
    "### Format\n",
    "sentence &lt;tab&gt; score &lt;newline&gt;\n",
    "\n",
    "### Details\n",
    "Score is either 1 (for positive) or 0 (for negative)\n",
    "\n",
    "The sentences come from three different websites/fields:\n",
    "- imdb.com\n",
    "- amazon.com\n",
    "- yelp.com\n",
    "\n",
    "For each website, there exist **500 positive** and **500 negative** sentences. Those were selected randomly for larger datasets of reviews.\n",
    "\n",
    "We attempted to select sentences that have a clearly positive or negative connotation, the goal was for no neutral sentences to be selected.\n",
    "\n",
    "For the full datasets look:\n",
    "\n",
    "- **imdb**: Maas et. al., 2011 _Learning word vectors for sentiment analysis_\n",
    "- **amazon**: McAuley et. al., 2013 _Hidden factors and hidden topics: Understanding rating dimensions with review text_\n",
    "- **yelp**: [Yelp dataset challenge](http://www.yelp.com/dataset_challenge)\n",
    "\n",
    "\n",
    "### Attribute Information\n",
    "The attributes are text sentences, extracted from reviews of products, movies, and restaurants\n",
    "\n",
    "### Relevant Papers\n",
    "**From Group to Individual Labels using Deep Features**, Kotzias et. al,. KDD 2015\n",
    "\n",
    "### Citation Request\n",
    "**From Group to Individual Labels using Deep Features**, Kotzias et. al,. KDD 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abNvVWdlLcfW"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:27:26.865620Z",
     "start_time": "2019-06-17T01:27:24.368522Z"
    },
    "id": "4BJWjM0zLcfZ"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "import regex as re\n",
    "import spacy\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzzk6JdcLcfh"
   },
   "source": [
    "## Load data\n",
    "\n",
    "Load Yelp, Amazon and Imdb Data into dataframes. Create the two column names 'text' and 'sentiment' for each dataframe.\n",
    "\n",
    "Hint: Source is separated by tabs and has no headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:29:38.157718Z",
     "start_time": "2019-06-17T01:29:38.152747Z"
    },
    "id": "GZUWhcCuLcfi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_text = '../DATA/yelp_labeled.txt'\n",
    "imdb_text = '../DATA/imdb_labeled_fixed.txt'\n",
    "amazon_text = '../DATA/amazon_cells_labeled.txt'\n",
    "\n",
    "# ANSWER\n",
    "df_yelp = pd.read_csv(yelp_text, sep = '\\t', header=None, names=['text', 'sentiment'])\n",
    "df_imdb = pd.read_csv(imdb_text, sep = '\\t', header=None, names=['text', 'sentiment'])\n",
    "df_amazon = pd.read_csv(amazon_text, sep = '\\t', header=None, names=['text', 'sentiment'])\n",
    "\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwa3MBrwLcfo"
   },
   "source": [
    "## Inspect the data\n",
    "\n",
    "Check your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: yelp [1000 row(s) x 2 col(s)]\n",
      "                                                text  sentiment source\n",
      "0                           Wow... Loved this place.          1   yelp\n",
      "1                                 Crust is not good.          0   yelp\n",
      "2          Not tasty and the texture was just nasty.          0   yelp\n",
      "3  Stopped by during the late May bank holiday of...          1   yelp\n",
      "4  The selection on the menu was great and so wer...          1   yelp\n",
      "---------------------------------------------------------------------------\n",
      "Dataset: imdb [1000 row(s) x 2 col(s)]\n",
      "                                                text  sentiment source\n",
      "0  A very, very, very slow-moving, aimless movie ...          0   imdb\n",
      "1  Not sure who was more lost - the flat characte...          0   imdb\n",
      "2  Attempting artiness with black & white and cle...          0   imdb\n",
      "3       Very little music or anything to speak of.            0   imdb\n",
      "4  The best scene in the movie was when Gerardo i...          1   imdb\n",
      "---------------------------------------------------------------------------\n",
      "Dataset: amazon [1000 row(s) x 2 col(s)]\n",
      "                                                text  sentiment  source\n",
      "0  So there is no way for me to plug it in here i...          0  amazon\n",
      "1                        Good case, Excellent value.          1  amazon\n",
      "2                             Great for the jawbone.          1  amazon\n",
      "3  Tied to charger for conversations lasting more...          0  amazon\n",
      "4                                  The mic is great.          1  amazon\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = {'yelp': df_yelp, 'imdb': df_imdb, 'amazon': df_amazon}\n",
    "for ds in dfs.keys():\n",
    "    print('Dataset: %s [%d row(s) x %d col(s)]' % (ds, dfs[ds].shape[0], dfs[ds].shape[1]))\n",
    "    dfs[ds].columns = ['text', 'sentiment']\n",
    "    dfs[ds]['source'] = ds\n",
    "    print(dfs[ds].head())\n",
    "    print('-' * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meEtfGfELcf4"
   },
   "source": [
    "## Merge the data\n",
    "\n",
    "Merge all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:30:01.495935Z",
     "start_time": "2019-06-17T01:30:01.492941Z"
    },
    "id": "NddGh-EQLcfq"
   },
   "outputs": [],
   "source": [
    "df = pd.concat(dfs.values(), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBIFtbMALcf8"
   },
   "source": [
    "## Export the data\n",
    "\n",
    "Export merged datasets to as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:31:16.041727Z",
     "start_time": "2019-06-17T01:31:16.037738Z"
    },
    "id": "n8OLkaALLcf9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "df.to_csv('merged_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzA4FQsPLcgA"
   },
   "source": [
    "## Prepare the stage\n",
    "- Load spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:31:19.686599Z",
     "start_time": "2019-06-17T01:31:18.952239Z"
    },
    "id": "wVMTSDYQLcgB"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YguMrtDuLcgD"
   },
   "source": [
    "## Prepare the text\n",
    "All the text handling and preparation concerned with the changes and modifications from the raw source text to a format that will be used for the actual processing, things like:\n",
    "- handle encoding\n",
    "- handle extraneous and international characters\n",
    "- handle symbols\n",
    "- handle metadata and embedded information\n",
    "- handle repetitions (such multiple spaces or newlines)\n",
    "\n",
    "Clean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:31:31.608285Z",
     "start_time": "2019-06-17T01:31:31.601306Z"
    },
    "id": "GlsKSvonLcgD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:32:56.768268Z",
     "start_time": "2019-06-17T01:32:56.765283Z"
    },
    "id": "upPa3YmmLcgF"
   },
   "outputs": [],
   "source": [
    "# Apply the clean_text function to your dataset.\n",
    "df['text'] = df.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za_6vt3MLcgH"
   },
   "source": [
    "## Work the text\n",
    "Using techniques learned in previous labs, remove StopWords, punctuation, and digits. Entities can be retained. Return the lemmatized form of any remaining words in lower case form.\n",
    "\n",
    "This removes meaningless information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:32:58.911623Z",
     "start_time": "2019-06-17T01:32:58.897659Z"
    },
    "id": "sh_uDWcCLcgI"
   },
   "outputs": [],
   "source": [
    "# Complete the function\n",
    "def convert_text(text):\n",
    "    '''\n",
    "    Use techniques learned in previous labs.\n",
    "    1) Remove StopWords, Punctuation and digits.\n",
    "    2) Retain entities.\n",
    "    3) Return the lemmatized form of remaining words in lower case form.\n",
    "\n",
    "    '''\n",
    "    sent= nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct or w.is_digit:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:33:42.014624Z",
     "start_time": "2019-06-17T01:33:01.620538Z"
    },
    "id": "0vDv55U1LcgK",
    "outputId": "6ae31463-3509-4ea6-934a-6ea1ff1f6b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.8 s\n",
      "Wall time: 9.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['short'] = df['text'].apply(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:13.381487Z",
     "start_time": "2019-06-17T01:35:13.362526Z"
    },
    "id": "faiuJfunLcgM",
    "outputId": "67d67ec3-44c6-4315-ef42-7467f69494d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>I liked the way Dustin Hoffman's character was...</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "      <td>like way dustin hoffman character ready stay s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Don't be afraid of subtitles........ its worth...</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "      <td>afraid subtitle worth little aversion therapy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>The movie lacks visual interest, drama, expres...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie lack visual interest drama expression fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>The sides are delish - mixed mushrooms, yukon ...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>side delish mix mushroom yukon gold puree whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>The waitress was friendly and happy to accomod...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>waitress friendly happy accomodate vegan veggi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>This is probably the most irritating show I ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "      <td>probably irritating see entire life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>the potatoes were great and so was the biscuit.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>potato great biscuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>Then a few days later the a puff of smoke came...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>day later puff smoke come phone use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>Lasted one day and then blew up.</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>last day blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>I asked multiple times for the wine list and a...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>ask multiple time wine list time ignore go hos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment  source  \\\n",
       "1763  I liked the way Dustin Hoffman's character was...          1    imdb   \n",
       "1652  Don't be afraid of subtitles........ its worth...          1    imdb   \n",
       "1245  The movie lacks visual interest, drama, expres...          0    imdb   \n",
       "209   The sides are delish - mixed mushrooms, yukon ...          1    yelp   \n",
       "591   The waitress was friendly and happy to accomod...          1    yelp   \n",
       "1513  This is probably the most irritating show I ha...          0    imdb   \n",
       "850     the potatoes were great and so was the biscuit.          1    yelp   \n",
       "2755  Then a few days later the a puff of smoke came...          0  amazon   \n",
       "2992                   Lasted one day and then blew up.          0  amazon   \n",
       "628   I asked multiple times for the wine list and a...          0    yelp   \n",
       "\n",
       "                                                  short  \n",
       "1763  like way dustin hoffman character ready stay s...  \n",
       "1652  afraid subtitle worth little aversion therapy ...  \n",
       "1245  movie lack visual interest drama expression fe...  \n",
       "209   side delish mix mushroom yukon gold puree whit...  \n",
       "591   waitress friendly happy accomodate vegan veggi...  \n",
       "1513              probably irritating see entire life    \n",
       "850                                potato great biscuit  \n",
       "2755                day later puff smoke come phone use  \n",
       "2992                                      last day blow  \n",
       "628   ask multiple time wine list time ignore go hos...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbwjijVyLcgP"
   },
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:24.658233Z",
     "start_time": "2019-06-17T01:35:24.649227Z"
    },
    "id": "Hj2aoBqqLcgV"
   },
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = df['short']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Apply a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr_VmeNMLcgY"
   },
   "source": [
    "## Create a Bag-of-Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:32.373670Z",
     "start_time": "2019-06-17T01:35:32.369681Z"
    },
    "id": "Rhd__LD6LcgZ"
   },
   "outputs": [],
   "source": [
    "# create a matrix of word counts from the text\n",
    "counts = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:35.842101Z",
     "start_time": "2019-06-17T01:35:35.784219Z"
    },
    "id": "23CpVgPxLcgb"
   },
   "outputs": [],
   "source": [
    "# do the actual counting\n",
    "A = counts.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 3570)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:38.590493Z",
     "start_time": "2019-06-17T01:35:38.586469Z"
    },
    "id": "c_rue57RLcgd"
   },
   "outputs": [],
   "source": [
    "# create a classifier using SVC\n",
    "classifier = SVC(kernel='linear', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:41.929126Z",
     "start_time": "2019-06-17T01:35:41.745617Z"
    },
    "id": "Lou4xDLmLcgh",
    "outputId": "cbc743d3-09c6-448c-bd75-75f9d5366211"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:47.210207Z",
     "start_time": "2019-06-17T01:35:47.199250Z"
    },
    "id": "inkg1KTiLcgi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = counts.transform(X_test).toarray()\n",
    "type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:51.223067Z",
     "start_time": "2019-06-17T01:35:51.209096Z"
    },
    "id": "dg-HpdJ0Lcgk"
   },
   "outputs": [],
   "source": [
    "# make predictions based on the test data\n",
    "# predictions = classifier.predict(B.todense())\n",
    "predictions = classifier.predict(B)\n",
    "\n",
    "# store probabilities of predictions being 1\n",
    "probabilities = classifier.predict_proba(B)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:54.779047Z",
     "start_time": "2019-06-17T01:35:54.771069Z"
    },
    "id": "t0HJn9qhLcgm",
    "outputId": "0bc7328f-ed1e-4259-e02f-981413ab8bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-Ia6a8ULcgn"
   },
   "source": [
    "## Repeat using TF-IDF\n",
    "TF-IDF = Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:36:02.927008Z",
     "start_time": "2019-06-17T01:36:02.785387Z"
    },
    "id": "7Tg1dwSpLcgo",
    "outputId": "256d6cbb-663b-4f6d-daa6-c609c9ec18ad"
   },
   "outputs": [],
   "source": [
    "# create a matrix of word counts from the text\n",
    "# use TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "# do the actual counting\n",
    "A = tfidf.fit_transform(X_train, y_train)\n",
    "\n",
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = tfidf.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make predictions based on the test data\n",
    "predictions = classifier.predict(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# store probabilities of predictions being 1\n",
    "probabilities = classifier.predict_proba(B)[:, 1]\n",
    "\n",
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXbw_oNdZAHv"
   },
   "source": [
    "## Defining a helper function to show results and charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:35:22.212854Z",
     "start_time": "2019-06-17T01:35:22.040284Z"
    },
    "id": "eJZpD903LcgQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_summary_report(actual, prediction, probabilities):\n",
    "\n",
    "    if isinstance(actual, pd.Series):\n",
    "        actual = actual.values.astype(int)\n",
    "    prediction = prediction.astype(int)\n",
    "\n",
    "    accuracy_ = accuracy_score(actual, prediction)\n",
    "    precision_ = precision_score(actual, prediction)\n",
    "    recall_ = recall_score(actual, prediction)\n",
    "    roc_auc_ = roc_auc_score(actual, probabilities)\n",
    "\n",
    "    print('Accuracy : %.4f [TP / N] Proportion of predicted labels that match the true labels. Best: 1, Worst: 0' % accuracy_)\n",
    "    print('Precision: %.4f [TP / (TP + FP)] Not to label a negative sample as positive.        Best: 1, Worst: 0' % precision_)\n",
    "    print('Recall   : %.4f [TP / (TP + FN)] Find all the positive samples.                     Best: 1, Worst: 0' % recall_)\n",
    "    print('ROC AUC  : %.4f                                                                     Best: 1, Worst: < 0.5' % roc_auc_)\n",
    "    print('-' * 107)\n",
    "    print('TP: True Positives, FP: False Positives, TN: True Negatives, FN: False Negatives, N: Number of samples')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    mat = confusion_matrix(actual, prediction)\n",
    "\n",
    "    # Precision/Recall\n",
    "    precision, recall, _ = precision_recall_curve(actual, probabilities)\n",
    "    average_precision = average_precision_score(actual, probabilities)\n",
    "\n",
    "    # Compute ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(actual, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (18, 6))\n",
    "    fig.subplots_adjust(left = 0.02, right = 0.98, wspace = 0.2)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    sns.heatmap(mat.T, square = True, annot = True, fmt = 'd', cbar = False, cmap = 'Blues', ax = ax[0])\n",
    "\n",
    "    ax[0].set_title('Confusion Matrix')\n",
    "    ax[0].set_xlabel('True label')\n",
    "    ax[0].set_ylabel('Predicted label')\n",
    "\n",
    "    # Precision/Recall\n",
    "    step_kwargs = {'step': 'post'}\n",
    "    ax[1].step(recall, precision, color = 'b', alpha = 0.2, where = 'post')\n",
    "    ax[1].fill_between(recall, precision, alpha = 0.2, color = 'b', **step_kwargs)\n",
    "    ax[1].set_ylim([0.0, 1.0])\n",
    "    ax[1].set_xlim([0.0, 1.0])\n",
    "    ax[1].set_xlabel('Recall')\n",
    "    ax[1].set_ylabel('Precision')\n",
    "    ax[1].set_title('2-class Precision-Recall curve')\n",
    "\n",
    "    # ROC\n",
    "    ax[2].plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    ax[2].plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n",
    "    ax[2].set_xlim([0.0, 1.0])\n",
    "    ax[2].set_ylim([0.0, 1.0])\n",
    "    ax[2].set_xlabel('False Positive Rate')\n",
    "    ax[2].set_ylabel('True Positive Rate')\n",
    "    ax[2].set_title('Receiver Operating Characteristic')\n",
    "    ax[2].legend(loc = 'lower right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return (accuracy_, precision_, recall_, roc_auc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5PTu402Lcgq"
   },
   "source": [
    "## Repeating it all for comparision\n",
    "Repeat the whole lot in one big block using the show_summary_report function.\n",
    "\n",
    "Find 'Accuracy', 'Precision', 'Recall', 'ROC_AUC' using CountVectorizer and TfidfVectorizer and keep the result in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:37:30.200048Z",
     "start_time": "2019-06-17T01:37:30.197044Z"
    },
    "id": "_98CzdfPLcgq"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2024 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "IOD2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
